---
title: <span style="color:#034a94"> **Software R**</span>
author: "Modelos Estadisticos para la toma de decisiones"
output: html_document
css: style.css
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = NA)
# colores
c0= "#b0394a"
c1= "#ad6395"
c2= "#a391c4"
c3= "#8acfe6"
c4= "#646420"
c5= "#db524f"
paleta4=c("#0d3b66", "#faf0ca", "#f4d35e", "#ee964d")
library(paqueteMOD)
library(tidyverse)
library(MASS)
data("apartamentos") # 54 x 10 (precio, area,cons) 

```

</br></br>

Con el propósito de revisar los códigos en R relacionados con los procesos descritos en la unidad se tomará información de las dos primeras variables contenidas en la base `ventas` contenida en el `paqueteMOD` 

* **vendedor**  : id del vendedor 
* **ventas**     : valor de las ventas
* **clientes** :  número de clientes

</br></br>

### <span style="color:#034a94">**Carga de los datos**</span>

```{r, eval=FALSE}
library(paqueteMOD)
library(tidyverse)
data(ventas)

```

</br></br>

### <span style="color:#034a94">**Descripción de las variables**</span>

```{r}
summarytools::descr(ventas[,2:3])
```

</br></br>


```{r}
library(ggplot2)
library(patchwork)
p1 = ggplot(ventas, aes(x=clientes))+geom_boxplot()
p2 = ggplot(ventas, aes(x=ventas))+ geom_boxplot()
p3 = ggplot(ventas, aes(x=clientes))+geom_density()
p4 = ggplot(ventas, aes(x=ventas))+ geom_density()

(p1 + p2)/(p3 + p4)
```

</br></br>


### <span style="color:#034a94">**Diagrama de dispersión**</span>

En este diagrama se pretende visualizar la relación existente entre las variables, si se puede ajustar a una linea recta o si por el contrario se debe realizar una transformación.

Se pueden utilizar las funciones: 

* `plot(x,y)` 
* `gplot(data, aes(x,y))+ geom_point()` 


```{r}
library(ggplot2)
ggplot(ventas, aes(x=clientes, y=ventas))+
  geom_point()
```

</br></br>

### <span style="color:#034a94">**Normalidad de las variables**</span>

```{r}
shapiro.test(ventas$clientes)
shapiro.test(ventas$ventas)
```

</br></br>

### <span style="color:#034a94">**Inferencia sobre  la correlación**</span>

```{r}
cor.test(ventas$ventas, ventas$clientes)

```

</br></br>

### <span style="color:#034a94">**Estimación del modelo por MCO**</span>

Para la estimación del modelo requerimos las funciones:

* `modelo <- lm(formula, data, weights)` : estima el modelo MCO
* `summary(modelo)                     ` : visualiza el objeto  

```{r, message=FALSE, warning=FALSE}
modelo1=lm(ventas ~ clientes, ventas)
summary(modelo1)
```

La anterior salida se divide en cuatro partes:
</br></br>

#### <span style="color:#034a94">**Forma funcional del modelo**</span>

<pre>

Call:
lm(formula = ventas ~ clientes, data = ventas)
</pre>

</br>

#### <span style="color:#034a94">**Resumen de los residuales**</span>

<pre>
Residuals:
    Min      1Q  Median      3Q     Max 
-11.873  -2.861   0.255   3.511  10.595 
</pre>

</br></br>

#### <span style="color:#034a94">**Estimación MCO de los coeficientes $\beta_{0}$ y $\beta_{1}$**</span>

<pre>
Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  19.9800     4.3897   4.552 0.000544 ***
clientes      0.2606     0.0420   6.205 3.19e-05 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
</pre>

</br></br>

#### <span style="color:#034a94">**Indicadores de significancia del modelo** </span>

<pre>
Residual standard error: 6.72 on 13 degrees of freedom
Multiple R-squared:  0.7476,	Adjusted R-squared:  0.7282 
F-statistic:  38.5 on 1 and 13 DF,  p-value: 3.193e-05
</pre>

</br></br>

### <span style="color:#034a94">**Validación de los supuestos sobre los errores**</span>


</br>

Inicialmente se revisar los gráficos generados con el objeto `modelo1`

```{r}
par(mfrow = c(2, 2))
plot(modelo1)
```

</br></br>

Ahora utilizando pruebas de hipótesis 

### <span style="color:#034a94">**Supuesto de normalidad de los errores**</span>

```{r, message=FALSE, warning=FALSE}
e= modelo1$residuals

# Ho: los errores tienen distribución normal
shapiro.test(e)
```

</br></br>


### <span style="color:#034a94">**Supuesto de independencia de errores**</span>

```{r, message=FALSE, warning=FALSE}
library(lmtest)
# Ho: los errores sin independientes ( no estan relacionados)
dwtest(modelo1)
```

</br></br>


### <span style="color:#034a94">**Supuesto de varianza constante**</span>

```{r, message=FALSE, warning=FALSE}
# Ho: la varianza de los erroes es constante
gqtest(modelo1)
```

</br></br>

### <span style="color:#034a94">**Supuesto de linealidad del modelo**</span>

</br></br>


### <span style="color:#034a94">**Representación gráfica del modelo**</span>

```{r}
ggplot(ventas, aes(clientes, ventas)) +
            geom_point() + 
            geom_smooth(method = "lm",  level = 0.95, formula = y ~ x)
```


</br></br>

### <span style="color:#034a94">**Tranformaciones**

En caso de requerir transfomaciones a las variables del modelo planteado con el fin demejorar sus indicadores y el cumplimiento loa supuestos.

</br></br>

##### <span style="color:#034a94">**Modelo log-lin**</span>

```{r, message=FALSE, warning=FALSE}
modelo2=lm(log(ventas) ~ clientes, ventas)
summary(modelo2)
```

</br></br>

##### <span style="color:#034a94">**Modelo lin-log**</span>

```{r, message=FALSE, warning=FALSE}
modelo3=lm(ventas ~ log(clientes), ventas)
summary(modelo3)
```

</br></br>

##### <span style="color:#034a94">**Modelo log-log**</span>

```{r, message=FALSE, warning=FALSE}
modelo4=lm(log(ventas) ~ log(clientes), ventas)
summary(modelo4)
```

</br></br>

### <span style="color:#034a94">**Comparación de modelos**</span>

```{r, warning=FALSE, message=FALSE}
library(stargazer)
#stargazer(modelo1, modelo2, modelo3, modelo4,type="html", title="Comparación de modelos")
stargazer(modelo1, modelo2, modelo3, modelo4, type="text", df=FALSE)
```

Al comparar los valores de $R^{2}$, el **modelo1** presenta el mayor porcentaje de explicación de la variabilidad de $Y$


</br></br>

### <span style="color:#034a94">**Indicador AIC**</span> 

```{r}
AIC(modelo1, modelo2, modelo3, modelo4)
```

</br></br>

### <span style="color:#034a94">**Predicción de $E[Y|x_{o}]$**</span>

```{r}
predict(modelo1, data.frame(clientes=20), interval = "confidence", level = 0.95)
```

</br></br>

### <span style="color:#034a94">**Predicción de  $Y_{0}$**</span>


```{r}
predict(modelo1, data.frame(clientes=20), interval = "prediction", level = 0.95)
```

</br></br>

## <span style="color:#034a94">**Evaluación de la linealidad del modelo**</span>

</br>

Para ello utilizamos la función `boxcox()` del paquete `MASS`

</br>

```{r}
library(paqueteMOD)
data(ventas) 
modelo1=lm(ventas ~ clientes, ventas)
summary(modelo1)
par(mfrow = c(1,2))
boxcox(lm(ventas$ventas ~ ventas$clientes), lambda = -2:2)
#Se repite el proceso pero esta vez estrechando el rango de valores de lambda 
bc<-boxcox(lm(ventas$ventas ~ ventas$clientes), lambda = 0:2)
(lambda <- bc$x[which.max(bc$y)])
```
</br>

El valor de $\lambda = 1.212121 $ indica que la variable dependiente debe continuar en la forma lineal $Y^{1}$



